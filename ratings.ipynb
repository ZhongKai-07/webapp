{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_github_pat():\n",
    "    with open(\"pat.txt\", \"r\") as file:\n",
    "        pat = file.read().strip()\n",
    "    return pat\n",
    "\n",
    "\n",
    "access_token = get_github_pat()\n",
    "\n",
    "\n",
    "def github_graphql(query):\n",
    "    url = \"https://api.github.com/graphql\"\n",
    "    json = {\"query\": query}\n",
    "    headers = {\"Authorization\": \"token %s\" % access_token}\n",
    "\n",
    "    r = requests.post(url=url, json=json, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def github_rest_get(url):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "        #  \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_dict = {\n",
    "    \"LukvonStrom\": \"Lukas\",\n",
    "    \"Sree5835\": \"Sree\",\n",
    "    \"HanchengZuo\": \"Hancheng\",\n",
    "    \"xiatianrui1110\": \"Tianrui\",\n",
    "    \"Cenxn\": \"Mingzirui\",\n",
    "    \"sudoPom\": \"Ponmile\",\n",
    "    \"wqt123\": \"Qitian\",\n",
    "    \"jasonho2582001\": \"Jason\",\n",
    "    \"james-parky\": \"James\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PVT_kwDOCQB6_84AYRas\n",
      "{'data': {'node': {'items': {'nodes': [{'id': 'PVTI_lADOCQB6_84AYRaszgMNgPQ', 'fieldValues': {'nodes': [{}, {}, {'text': 'Modify the deployment view of crane spotting system', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Modify the deployment view of crane spotting system', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-26T00:35:37Z', 'updatedAt': '2024-01-26T00:35:41Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMB3BQ', 'fieldValues': {'nodes': [{}, {'text': 'Dataset Visualization', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Dataset Visualization', 'body': '', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-18T21:25:37Z', 'updatedAt': '2024-01-18T21:25:49Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL-urY', 'fieldValues': {'nodes': [{}, {'text': 'Analysing surface features on the Isle of Wight in jupyter', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Analysing surface features on the Isle of Wight in jupyter', 'body': '', 'assignees': {'nodes': [{'login': 'HanchengZuo'}]}, 'createdAt': '2024-01-17T10:56:33Z', 'updatedAt': '2024-01-17T10:56:33Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMAvWQ', 'fieldValues': {'nodes': [{}, {'text': 'Migrate to VectorMaps (mapbox-gl) in parallel to compare to leaflet', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Migrate to VectorMaps (mapbox-gl) in parallel to compare to leaflet', 'body': '', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-18T10:23:36Z', 'updatedAt': '2024-01-18T10:23:36Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMCEFk', 'fieldValues': {'nodes': [{}, {}, {'text': 'Set up generating docs on push', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Set up generating docs on push', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-19T11:12:22Z', 'updatedAt': '2024-01-23T20:18:57Z', 'closedAt': '2024-01-23T20:18:57Z', 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMEs5c', 'fieldValues': {'nodes': [{}, {}, {'text': 'Coding the landcover datasets on GEE', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Coding the landcover datasets on GEE', 'assignees': {'nodes': [{'login': 'HanchengZuo'}]}, 'createdAt': '2024-01-22T14:53:20Z', 'updatedAt': '2024-01-22T14:53:20Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMF_K8', 'fieldValues': {'nodes': [{}, {}, {'text': 'Implement logging for drop zone system', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Implement logging for drop zone system', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-22T14:53:03Z', 'updatedAt': '2024-01-22T15:44:17Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGlk8', 'fieldValues': {'nodes': [{}, {}, {'text': 'CI/CD Pipeline Setup', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'CI/CD Pipeline Setup', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T16:07:53Z', 'updatedAt': '2024-01-23T19:10:53Z', 'closedAt': '2024-01-23T19:10:53Z', 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIWT8', 'fieldValues': {'nodes': [{}, {'text': 'Train an initial model using vertex ai', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Train an initial model using vertex ai', 'body': '', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-23T13:17:12Z', 'updatedAt': '2024-01-23T13:17:12Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMBs7o', 'fieldValues': {'nodes': [{}, {}, {'text': 'Integrate the dataset and Distributed the dataset', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Integrate the dataset and Distributed the dataset', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-22T14:52:12Z', 'updatedAt': '2024-01-22T14:52:12Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIWW0', 'fieldValues': {'nodes': [{}, {'text': 'Train an initial model using vertex ai', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Train an initial model using vertex ai', 'body': '', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-23T13:17:41Z', 'updatedAt': '2024-01-23T13:17:41Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQWUw', 'fieldValues': {'nodes': [{}, {}, {'text': 'Add frontend functionality to select multiple timestamps from which to render cranes on the map.', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Add frontend functionality to select multiple timestamps from which to render cranes on the map.', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-28T23:16:39Z', 'updatedAt': '2024-01-28T23:17:27Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': 'A user can select multiple timestamps from the set of available days and all cranes appear in the info list, on the map, and their images appear in the gallery.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQWVo', 'fieldValues': {'nodes': [{}, {}, {'text': 'Unclutter the crane spotting frontend map by implementing clustering with mapbox', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Unclutter the crane spotting frontend map by implementing clustering with mapbox', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-28T23:16:29Z', 'updatedAt': '2024-01-28T23:18:26Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': 'Use mapboxgl clustering to unclutter the map at certain zoom levels. Cranes should still be easily identifiable at a reasonable zoom, but when it is unclear, they should be clustered with a indication as to how many are abstracted.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNfb8', 'fieldValues': {'nodes': [{}, {}, {'text': 'Research, discuss, and modify the Crane Spotting back end architecture.', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Research, discuss, and modify the Crane Spotting back end architecture.', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-26T00:17:51Z', 'updatedAt': '2024-01-26T00:20:10Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGltQ', 'fieldValues': {'nodes': [{}, {}, {'text': 'Initialize the VertexAI platform', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Initialize the VertexAI platform', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-22T16:08:39Z', 'updatedAt': '2024-01-22T16:08:40Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMBs-A', 'fieldValues': {'nodes': [{}, {}, {'text': 'Produce alternative solution for current chosen camera', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Produce alternative solution for current chosen camera', 'assignees': {'nodes': [{'login': 'sudoPom'}]}, 'createdAt': '2024-01-22T14:52:32Z', 'updatedAt': '2024-01-22T14:52:32Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMBs78', 'fieldValues': {'nodes': [{}, {}, {'text': 'Integrate the dataset and Distributed the dataset', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Integrate the dataset and Distributed the dataset', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-22T14:52:24Z', 'updatedAt': '2024-01-26T09:50:43Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL7cLM', 'fieldValues': {'nodes': [{}, {}, {'text': 'Explore Google Earth Engine data in notebook', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Explore Google Earth Engine data in notebook', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-22T15:45:09Z', 'updatedAt': '2024-01-22T15:45:09Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMEipU', 'fieldValues': {'nodes': [{}, {}, {'text': 'Identify EE datasets relevant to dropzone mapping system', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Identify EE datasets relevant to dropzone mapping system', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-22T14:53:27Z', 'updatedAt': '2024-01-22T14:53:27Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIq94', 'fieldValues': {'nodes': [{}, {}, {'text': 'Investigate caching osmnx querying for dropzone', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Investigate caching osmnx querying for dropzone', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-23T15:57:16Z', 'updatedAt': '2024-01-24T11:06:12Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMB4k0', 'fieldValues': {'nodes': [{}, {}, {'text': 'Set up PostGIS DB for cached drop zones', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Set up PostGIS DB for cached drop zones', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-22T14:52:58Z', 'updatedAt': '2024-01-24T09:36:08Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': 'Dockerfile should work out of the box.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL7fsM', 'fieldValues': {'nodes': [{}, {'text': 'Reformating the dataset annotation for vision api', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Reformating the dataset annotation for vision api', 'body': 'https://universe.roboflow.com/fyp-h6hxz/tower-crane-component/dataset/1', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-15T17:37:51Z', 'updatedAt': '2024-01-15T17:38:08Z', 'bodyText': 'https://universe.roboflow.com/fyp-h6hxz/tower-crane-component/dataset/1'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL4Lk4', 'fieldValues': {'nodes': [{}, {'text': 'Find and construct Dataset Demo', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Find and construct Dataset Demo', 'body': '', 'assignees': {'nodes': [{'login': 'Cenxn'}, {'login': 'sudoPom'}, {'login': 'wqt123'}, {'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-12T14:13:05Z', 'updatedAt': '2024-01-15T16:18:40Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL4Ll8', 'fieldValues': {'nodes': [{}, {'text': 'Produce Shopping List', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Produce Shopping List', 'body': '', 'assignees': {'nodes': [{'login': 'Cenxn'}, {'login': 'sudoPom'}, {'login': 'wqt123'}, {'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-12T14:13:15Z', 'updatedAt': '2024-01-12T14:13:15Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL5ZBY', 'fieldValues': {'nodes': [{}, {'text': 'EPIC: Initial OSM Feature Extractor', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'EPIC: Initial OSM Feature Extractor', 'body': '', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-13T21:39:44Z', 'updatedAt': '2024-01-13T21:39:44Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGoqk', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Fix/add correct images', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/9', 'title': 'Fix/add correct images', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-22T16:27:11Z', 'updatedAt': '2024-01-23T18:35:07Z', 'closedAt': '2024-01-23T18:35:07Z', 'headRefName': 'fix/add-correct-images', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\nThe images did not update, as the dataset was flawed. This PR fixes it.\\nChecklist\\n\\n I have commented my code, particularly in hard-to-understand areas.\\n Already rebased against main branch.\\n\\nScreenshots\\nProvide screenshots or videos of the changes made if any.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL5tP4', 'fieldValues': {'nodes': [{}, {'text': 'Summarize the tasks completed by the crane spotting sub-team during week 1 for display', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Summarize the tasks completed by the crane spotting sub-team during week 1 for display', 'body': '', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-14T14:29:34Z', 'updatedAt': '2024-01-14T14:30:16Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL7g1k', 'fieldValues': {'nodes': [{}, {'text': 'Explore OSM data in notebook', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Explore OSM data in notebook', 'body': '', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-15T17:51:00Z', 'updatedAt': '2024-01-15T17:51:00Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL7iLg', 'fieldValues': {'nodes': [{}, {'text': 'Reformating the dataset annotation for vision api', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Reformating the dataset annotation for vision api', 'body': 'https://universe.roboflow.com/university-of-malta-sz1l8/crane-finder-khyeg', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-15T18:08:26Z', 'updatedAt': '2024-01-15T18:09:04Z', 'bodyText': 'https://universe.roboflow.com/university-of-malta-sz1l8/crane-finder-khyeg'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL5rr0', 'fieldValues': {'nodes': [{}, {'text': 'Initialize dropzone with GoogleCloudPlatform/functions-framework-python/ and provide basic framework', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Initialize dropzone with GoogleCloudPlatform/functions-framework-python/ and provide basic framework', 'body': '', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-14T13:41:31Z', 'updatedAt': '2024-01-14T13:41:54Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGjzQ', 'fieldValues': {'nodes': [{}, {}, {'text': 'Initialize the VertexAI platform', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Initialize the VertexAI platform', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-22T16:08:15Z', 'updatedAt': '2024-01-22T16:08:16Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNU_w', 'fieldValues': {'nodes': [{}, {}, {'text': 'Deploy and test the model', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Deploy and test the model', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-26T09:57:32Z', 'updatedAt': '2024-01-26T09:57:32Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNVBE', 'fieldValues': {'nodes': [{}, {}, {'text': 'Deploy and test the model', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Deploy and test the model', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-26T09:57:50Z', 'updatedAt': '2024-01-26T09:57:50Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGqkY', 'fieldValues': {'nodes': [{}, {}, {'text': 'Try to use vision api directly', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Try to use vision api directly', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-22T22:32:29Z', 'updatedAt': '2024-01-22T22:32:29Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGqp4', 'fieldValues': {'nodes': [{}, {}, {'text': 'Try to use vision api directly', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Try to use vision api directly', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-22T22:32:40Z', 'updatedAt': '2024-01-22T22:32:40Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIoYM', 'fieldValues': {'nodes': [{}, {}, {'text': 'Use Spring Boot to initially create a project and attempt to invoke Google Cloud Storage (GCS)', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Use Spring Boot to initially create a project and attempt to invoke Google Cloud Storage (GCS)', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-23T15:37:57Z', 'updatedAt': '2024-01-26T00:15:55Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL9oAE', 'fieldValues': {'nodes': [{}, {'text': 'Reformat dataset annotation for vision API', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}, {}]}, 'content': {'title': 'Reformat dataset annotation for vision API', 'body': \"Although we don't have access to the GCP or a camera for input data, we can at least start collecting the relevant images and annotations we will use to train our model in the future.\\n\\nThe format of the annotations online does not match the format required by Google's Vision API so this task involves writing a script that converts the online dataset annotations to the correct format.\\n\\nThe dataset can be found here:\\nhttps://universe.roboflow.com/uom-5zqae/crane-finder\", 'assignees': {'nodes': [{'login': 'sudoPom'}]}, 'createdAt': '2024-01-16T20:08:47Z', 'updatedAt': '2024-01-16T20:12:50Z', 'bodyText': \"Although we don't have access to the GCP or a camera for input data, we can at least start collecting the relevant images and annotations we will use to train our model in the future.\\nThe format of the annotations online does not match the format required by Google's Vision API so this task involves writing a script that converts the online dataset annotations to the correct format.\\nThe dataset can be found here:\\nhttps://universe.roboflow.com/uom-5zqae/crane-finder\"}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL7gRk', 'fieldValues': {'nodes': [{}, {'text': 'Reformating the dataset annotation for vision api', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Reformating the dataset annotation for vision api', 'body': 'The link of dataset: https://universe.roboflow.com/cv-qnffv/crane-detection-jckjz', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-15T17:44:24Z', 'updatedAt': '2024-01-15T17:44:50Z', 'bodyText': 'The link of dataset: https://universe.roboflow.com/cv-qnffv/crane-detection-jckjz'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMF-yQ', 'fieldValues': {'nodes': [{}, {}, {'text': 'Code to buffer exclusion polygons for use in calculating viable drop zones.', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Code to buffer exclusion polygons for use in calculating viable drop zones.', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:22:25Z', 'updatedAt': '2024-01-22T11:22:25Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL4D_4', 'fieldValues': {'nodes': [{}, {}, {'text': 'EPIC: Complete initial Webapp setup', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'EPIC: Complete initial Webapp setup', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T14:53:13Z', 'updatedAt': '2024-01-23T19:11:30Z', 'closedAt': '2024-01-23T19:11:30Z', 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgL9XCg', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Slight refactor and beginning of styling from figma wireframes. ', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/1', 'title': 'Slight refactor and beginning of styling from figma wireframes. ', 'author': {'login': 'james-parky'}, 'createdAt': '2024-01-16T16:29:58Z', 'updatedAt': '2024-01-25T14:21:31Z', 'closedAt': '2024-01-25T14:21:31Z', 'headRefName': 'ui-design', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Initial styling for home page and cranespotting page. Navbar refactored and styled. NavbarItem created. Switched to nextjs  rather than html native  for optimisation. (required by eslint)\\nCurrently styling is done in css but will be changed to tailwindcss once final.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMHL8c', 'fieldValues': {'nodes': [{}, {}, {'text': 'Investigate using Java as the main language', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Investigate using Java as the main language', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T22:27:05Z', 'updatedAt': '2024-01-23T19:12:01Z', 'closedAt': '2024-01-23T19:12:01Z', 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGAHQ', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Critera'}]}, 'field': {'name': 'Labels'}}, {'text': 'Implement more robust global state management system for the webapp', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Implement more robust global state management system for the webapp', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:34:33Z', 'updatedAt': '2024-01-27T13:10:18Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMC4I8', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'documentation'}]}, 'field': {'name': 'Labels'}}, {}, {'text': 'Add Sphinx Document generation', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/1', 'title': 'Add Sphinx Document generation', 'author': {'login': 'jasonho2582001'}, 'createdAt': '2024-01-19T11:07:43Z', 'updatedAt': '2024-01-22T15:03:34Z', 'closedAt': '2024-01-22T15:03:34Z', 'headRefName': 'docs', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'PR Description\\nThis PR introduces the Sphinx documentation generation library, allowing for documentation for all project module, classes and functions. The documentation also identifies docstrings following the Google docstring convention.\\nUpdates\\n\\nAdded set-up code for Sphinx documentation\\nConfigured Sphinx to auto-generate documentation for entire repo\\nAdded Read the Docs theme\\nUpdated README.txt for instructions for generating and viewing documentation\\n\\nScreenshots'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGjVE', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Critera'}]}, 'field': {'name': 'Labels'}}, {'text': 'Read up on OSM code and implement analytical drop zone identification', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Read up on OSM code and implement analytical drop zone identification', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-22T16:08:28Z', 'updatedAt': '2024-01-27T13:11:45Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQZrU', 'fieldValues': {'nodes': [{}, {}, {'text': 'figure out the solution for .shp osm dataset with poor data labeling', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'figure out the solution for .shp osm dataset with poor data labeling', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-29T00:43:48Z', 'updatedAt': '2024-01-29T00:43:48Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQZpM', 'fieldValues': {'nodes': [{}, {}, {'text': 'Create a db manager class for other objects to interact with stored data', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Create a db manager class for other objects to interact with stored data', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-29T00:43:57Z', 'updatedAt': '2024-01-29T00:43:57Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMI_co', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Critera'}]}, 'field': {'name': 'Labels'}}, {'text': 'Optimise the way and format of API response data', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Optimise the way and format of API response data', 'assignees': {'nodes': [{'login': 'HanchengZuo'}]}, 'createdAt': '2024-01-23T19:11:09Z', 'updatedAt': '2024-01-27T13:11:37Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMCF8M', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Set up PyLint, Black pre-commit hooks', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Set up PyLint, Black pre-commit hooks', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-19T11:12:29Z', 'updatedAt': '2024-01-27T00:39:30Z', 'closedAt': '2024-01-27T00:39:30Z', 'repository': {'name': 'dropzone'}, 'bodyText': '@jasonho2582001 from my experience, husky works best for this as it can accommodate changes and add them to the commit, unless the lint etc. outright fails. Its integrated in the webapp already.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMF--E', 'fieldValues': {'nodes': [{}, {}, {'text': 'Find a way to render different parts of an OSM map at different resolutions to save on computation time', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Find a way to render different parts of an OSM map at different resolutions to save on computation time', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:23:29Z', 'updatedAt': '2024-01-28T23:12:28Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': 'Investigate whether it is possible to choose resolution data from OSM.\\nIf so, create a layer in the dropzone processor would be able detect low feature density areas and use lower-than-regular resolution data from OSM. There should be a clear distinction between high and low resolution data, that saves a meaningul amount of response packet data.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMF_KE', 'fieldValues': {'nodes': [{}, {}, {'text': 'Final refactor of the webapp -- including full styling from wireframes.', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Final refactor of the webapp -- including full styling from wireframes.', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:25:19Z', 'updatedAt': '2024-01-28T23:15:22Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': 'Implement all styling from the figma wireframes into the pre-existing frontend code.\\n\\n\\nRefactor frontend code for complete code consistency, follow best practices to extract as many resuable components as possible.\\n\\n\\nAll functionality from pre-existing code remains without change.\\n\\n\\nCode is clean, readable and well documented.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGAr4', 'fieldValues': {'nodes': [{}, {}, {'text': 'Add webapp accessibility features', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Add webapp accessibility features', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:40:04Z', 'updatedAt': '2024-01-29T11:07:40Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': 'ensuring all content is visible to screen readers for those unable to use a mouse.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNgUU', 'fieldValues': {'nodes': [{}, {}, {'text': 'Learn relative knowledge about RTMP server', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Learn relative knowledge about RTMP server', 'assignees': {'nodes': [{'login': 'wqt123'}]}, 'createdAt': '2024-01-26T00:37:08Z', 'updatedAt': '2024-01-27T16:54:31Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': 'Accepetance Critera\\n\\nUnderstanding of RTMP Basics\\nUnderstanding of how to build a Simple RTMP Server\\nDrafting documentation file encompassing concepts learned'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMPgVw', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Modify response structure of `searchDropzones` API', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Modify response structure of `searchDropzones` API', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-27T13:25:42Z', 'updatedAt': '2024-01-27T15:04:59Z', 'closedAt': '2024-01-27T15:04:59Z', 'repository': {'name': 'dropzone'}, 'bodyText': 'Right now, the response structure of the searchDropzones API is not valid GeoJSON, since there can be instances of nested FeatureCollection objects. Rather than manually modify GeoJSON returned by APIs like OSMNX which may return FeatureCollection data  depending on the query, the team has agreed to instead allow the API response to be a generic JSON object with the following structure:\\n{\\n    \"Layer 1\":  {\\n      \"type\": \"Feature\",\\n      \"geometry\": {\\n        \"type\": \"Point\",\\n        \"coordinates\": [0, 0]\\n      }\\n    },\\n    \"Combined\": {\\n      \"type\": \"Feature\",\\n      \"geometry\": {\\n        \"type\": \"Point\",\\n        \"coordinates\": [0, 0]\\n      }\\n    }\\n}\\nThis response is valid JSON, but we don\\'t force a constraint on this to be GeoJSON, but the values of each key in the JSON object is valid GeoJSON on its own. The format still allows for clients to easily manipulate the data as required.\\nAcceptance Criteria\\n\\nUse Postman and validate that the return structure is as designed'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMAvPY', 'fieldValues': {'nodes': [{}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Criteria'}]}, 'field': {'name': 'Labels'}}, {'text': 'Setup Camera', 'field': {'name': 'Title'}}, {'name': 'BLOCKED', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Setup Camera', 'assignees': {'nodes': []}, 'createdAt': '2024-01-22T14:53:37Z', 'updatedAt': '2024-01-27T14:00:55Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMM9NY', 'fieldValues': {'nodes': [{}, {}, {'text': 'Fix compiler error', 'field': {'name': 'Title'}}, {'name': 'BLOCKED', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/22', 'title': 'Fix compiler error', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-25T17:12:51Z', 'updatedAt': '2024-01-25T17:19:28Z', 'closedAt': None, 'headRefName': 'feature/increase-test-coverage', 'headRepository': {'name': 'webapp'}, 'bodyText': 'fix compiler error'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGliI', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'CI/CD Pipeline Setup', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'CI/CD Pipeline Setup', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T16:07:39Z', 'updatedAt': '2024-01-23T12:12:06Z', 'closedAt': '2024-01-23T12:12:06Z', 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGlkA', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'CI/CD Pipeline Setup', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'CI/CD Pipeline Setup', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T16:07:46Z', 'updatedAt': '2024-01-23T18:25:47Z', 'closedAt': '2024-01-23T18:25:47Z', 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGooQ', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Feature/make active button visible', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/10', 'title': 'Feature/make active button visible', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-22T16:27:35Z', 'updatedAt': '2024-01-23T18:33:32Z', 'closedAt': '2024-01-23T18:33:32Z', 'headRefName': 'feature/make-active-button-visible', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\nMakes Active Button for dropzone visible.\\nChecklist\\n\\n I have commented my code, particularly in hard-to-understand areas.\\n Already rebased against main branch.\\n\\nScreenshots\\nProvide screenshots or videos of the changes made if any.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJALU', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Set up bumpversion for dropzones', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Set up bumpversion for dropzones', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-23T18:45:12Z', 'updatedAt': '2024-01-23T19:50:11Z', 'closedAt': '2024-01-23T19:50:11Z', 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNIzI', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Critera'}]}, 'field': {'name': 'Labels'}}, {'text': 'Adding GEE feature extractor', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Adding GEE feature extractor', 'assignees': {'nodes': [{'login': 'HanchengZuo'}]}, 'createdAt': '2024-01-27T13:11:17Z', 'updatedAt': '2024-01-27T13:11:22Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJAIM', 'fieldValues': {'nodes': [{}, {}, {'text': 'Add unit testing for dropzones', 'field': {'name': 'Title'}}, {'name': 'In Progress', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Add unit testing for dropzones', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-23T18:44:51Z', 'updatedAt': '2024-01-27T13:24:35Z', 'closedAt': None, 'repository': {'name': 'dropzone'}, 'bodyText': 'Acceptance Criteria\\n\\nPytest coverage at least 70% (as a baseline)'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJDwA', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'documentation'}]}, 'field': {'name': 'Labels'}}, {}, {'text': 'Update the OpenAPI Documentation with the data you are returning', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Update the OpenAPI Documentation with the data you are returning', 'assignees': {'nodes': [{'login': 'jasonho2582001'}]}, 'createdAt': '2024-01-23T19:16:13Z', 'updatedAt': '2024-01-29T01:30:10Z', 'closedAt': '2024-01-29T01:30:10Z', 'repository': {'name': 'openapi'}, 'bodyText': 'Acceptance Criteria:\\n\\nThe OpenAPI specification in UCL-Drone-Deliveries/openapi matches with the actual behaviour of the system.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIFJY', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'GitHub Actions Deployment Setup', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/15', 'title': 'GitHub Actions Deployment Setup', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-23T10:41:12Z', 'updatedAt': '2024-01-23T12:12:09Z', 'closedAt': '2024-01-23T12:12:05Z', 'headRefName': 'github-actions', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'closes #12'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMIKpM', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Add webapp CI/CD', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/13', 'title': 'Add webapp CI/CD', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-23T11:29:02Z', 'updatedAt': '2024-01-23T18:25:49Z', 'closedAt': '2024-01-23T18:25:46Z', 'headRefName': 'feature/ci-cd', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\ncloses #7\\nChecklist\\n\\n I have commented my code, particularly in hard-to-understand areas.\\n Already rebased against main branch.\\n\\nScreenshots\\nProvide screenshots or videos of the changes made if any.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJEqQ', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Switch CD to 2nd gen cloud functions, tracking https://github.com/google-github-actions/deploy-cloud-functions/issues/304', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Switch CD to 2nd gen cloud functions, tracking https://github.com/google-github-actions/deploy-cloud-functions/issues/304', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-25T10:22:11Z', 'updatedAt': '2024-01-26T13:22:31Z', 'closedAt': '2024-01-26T13:22:31Z', 'repository': {'name': 'dropzone'}, 'bodyText': 'Tracking google-github-actions/deploy-cloud-functions#304'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMK5T4', 'fieldValues': {'nodes': [{}, {}, {'text': 'Increase testcoverage for FE reasonably', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Increase testcoverage for FE reasonably', 'assignees': {'nodes': []}, 'createdAt': '2024-01-24T16:54:01Z', 'updatedAt': '2024-01-25T16:26:40Z', 'closedAt': '2024-01-25T16:26:40Z', 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMI_sE', 'fieldValues': {'nodes': [{}, {'text': 'Feature/make active button visible', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/15', 'title': 'Feature/make active button visible', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-23T18:37:19Z', 'updatedAt': '2024-01-23T18:42:12Z', 'closedAt': '2024-01-23T18:42:01Z', 'headRefName': 'feature/make-active-button-visible', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\nDescribe problems, if any, clearly and concisely.\\nSummarize the impact to the system.\\nPlease also include relevant motivation and context.\\nPlease include a summary of the technical solution and how it solves the problem.\\nChecklist\\n\\n I have commented my code, particularly in hard-to-understand areas.\\n Already rebased against main branch.\\n\\nScreenshots\\nProvide screenshots or videos of the changes made if any.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMGA0s', 'fieldValues': {'nodes': [{}, {}, {'labels': {'nodes': [{'name': 'Missing-Acceptance-Critera'}]}, 'field': {'name': 'Labels'}}, {'text': 'Add typescript auto document generation for webapp', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Add typescript auto document generation for webapp', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:41:10Z', 'updatedAt': '2024-01-27T13:10:34Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJDg8', 'fieldValues': {'nodes': [{}, {}, {'text': 'Investigate moving to a mapbox-gl react native component', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Investigate moving to a mapbox-gl react native component', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-23T19:13:49Z', 'updatedAt': '2024-01-27T14:00:38Z', 'closedAt': None, 'repository': {'name': 'webapp'}, 'bodyText': 'Magnus suggested using react \"native\" wrappers around mapbox-gl\\nThus this task has the following acceptance criteria:\\n\\nAssess feasibility and usability of these wrappers\\nTry to port the code if its feasible and a value-add'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQUG0', 'fieldValues': {'nodes': [{}, {}, {'text': 'Try to connect the interface backend project to the database', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Try to connect the interface backend project to the database', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-28T22:14:57Z', 'updatedAt': '2024-01-28T22:14:57Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQUBo', 'fieldValues': {'nodes': [{}, {}, {'text': 'Create a database instance via Cloud SQL service', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Create a database instance via Cloud SQL service', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-28T22:13:26Z', 'updatedAt': '2024-01-28T22:13:52Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJHFQ', 'fieldValues': {'nodes': [{}, {}, {'text': 'Introduce bumpversion', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/21', 'title': 'Introduce bumpversion', 'author': {'login': 'jasonho2582001'}, 'createdAt': '2024-01-23T19:48:38Z', 'updatedAt': '2024-01-23T19:50:13Z', 'closedAt': '2024-01-23T19:50:10Z', 'headRefName': 'bumpversion', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'PR Description\\nThis PR introduces setup for the bumpversion library, allowing for managing versions. We will use SEMVER conventions.\\nThis PR closes #18'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMKXTs', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Remove leaflet, improve mapbox error handling and improve performance/bundle size', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}, {}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/18', 'title': 'Remove leaflet, improve mapbox error handling and improve performance/bundle size', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-24T12:22:03Z', 'updatedAt': '2024-01-25T15:29:20Z', 'closedAt': '2024-01-25T15:29:16Z', 'headRefName': 'feature/remove-leaflet', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\n\\nRemoved Leaflet and only retained Mapbox Components\\nImproved graceful degradation for the Prod FE\\nAdded a mapbox secret in the CD pipeline\\nDecreased the bundle size and thus increased performance\\n\\ncloses #12\\ncloses #16\\ncloses #19\\nChecklist\\n\\n I have commented my code, particularly in hard-to-understand areas.\\n Already rebased against main branch.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMF_Bo', 'fieldValues': {'nodes': [{}, {'text': 'Finish figma wireframing for the webapp', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Finish figma wireframing for the webapp', 'body': '', 'assignees': {'nodes': [{'login': 'james-parky'}]}, 'createdAt': '2024-01-22T11:23:53Z', 'updatedAt': '2024-01-22T11:23:53Z', 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMKgy8', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Move mapbox-gl secret into GCP secret and only inject in buildtime', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Move mapbox-gl secret into GCP secret and only inject in buildtime', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-24T13:48:10Z', 'updatedAt': '2024-01-25T15:29:18Z', 'closedAt': '2024-01-25T15:29:18Z', 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMK5hI', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Increase test coverage ', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/webapp/pull/21', 'title': 'Increase test coverage ', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-24T16:55:54Z', 'updatedAt': '2024-01-25T16:27:30Z', 'closedAt': '2024-01-25T16:26:39Z', 'headRefName': 'feature/increase-test-coverage', 'headRepository': {'name': 'webapp'}, 'bodyText': 'Description & Technical Solution\\nIncreases Frontend Coverage and tests more branches.\\nCloses #20'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMHMq4', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Remove Leaflet components entirely', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Remove Leaflet components entirely', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-22T22:36:46Z', 'updatedAt': '2024-01-25T15:29:17Z', 'closedAt': '2024-01-25T15:29:17Z', 'repository': {'name': 'webapp'}, 'bodyText': 'We are set on Mapbox now as it seems.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMJCPc', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Fix Prod Degradation', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Fix Prod Degradation', 'assignees': {'nodes': [{'login': 'LukvonStrom'}]}, 'createdAt': '2024-01-23T19:01:23Z', 'updatedAt': '2024-01-25T15:29:18Z', 'closedAt': '2024-01-25T15:29:18Z', 'repository': {'name': 'webapp'}, 'bodyText': ''}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMMND8', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Port to Cloud Functions v2 ', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/23', 'title': 'Port to Cloud Functions v2 ', 'author': {'login': 'LukvonStrom'}, 'createdAt': '2024-01-25T10:38:55Z', 'updatedAt': '2024-01-26T13:22:30Z', 'closedAt': '2024-01-26T13:22:30Z', 'headRefName': 'feature/port-to-gcp-fn-v2', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'Port the Deployment to cloud functions v2 (for some reason the native github action does not support this since > 1yr).\\nIn addition publish it as deployment in Github.\\nAlso added a testscript which leverages curl to test for a successful deployment.\\ncloses #22'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMOQlk', 'fieldValues': {'nodes': [{}, {}, {'text': 'Implement Image Processor', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Implement Image Processor', 'assignees': {'nodes': [{'login': 'sudoPom'}]}, 'createdAt': '2024-01-27T13:10:49Z', 'updatedAt': '2024-01-27T14:01:32Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': 'The Image process needs to do the following:\\n\\nRepeatedly retrieve image frames from the RTMP stream.\\nPass captured frames to ML model and store annotated images in cloud storage.\\nProvide a topic for subscribers to request updates on processed images.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNVMM', 'fieldValues': {'nodes': [{}, {}, {'text': 'Find more dataset, processing the dataset,and augmentation and filter unneed data to improve the model accuracy', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Find more dataset, processing the dataset,and augmentation and filter unneed data to improve the model accuracy', 'assignees': {'nodes': [{'login': 'Cenxn'}]}, 'createdAt': '2024-01-26T09:58:56Z', 'updatedAt': '2024-01-27T14:01:13Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': 'This tasks involved the following process:\\n\\nAdded new data source into current dataset\\nMake data augmentation to CreneDetectionCV dataset (available on google cloud storage)\\nTraining new ML model with better ability to capture cranes in the distance\\n\\nAcceptance criteria:\\n\\nThe new model should have better detection ability than old one in terms of objects in the distance. The result should be cover by the prediction result of the two models.'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNVNk', 'fieldValues': {'nodes': [{}, {}, {'text': 'Setup the backend environment for the project running on the interface server ', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Setup the backend environment for the project running on the interface server ', 'assignees': {'nodes': [{'login': 'xiatianrui1110'}]}, 'createdAt': '2024-01-26T09:59:08Z', 'updatedAt': '2024-01-29T11:06:14Z', 'closedAt': None, 'repository': {'name': 'crane-spotting'}, 'bodyText': \"Set up the SpringBoot backend project.\\nThe strength of the Quartz framework lies in its powerful job scheduling capabilities, which are mainly used to schedule timed tasks in Java applications. However, we don't need to utilize this feature in our backend to take advantage of it, so I don't see the need to use Quartz.\"}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNJw4', 'fieldValues': {'nodes': [{}, {}, {'text': 'Refine respons data and Added geeExtractor', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/24', 'title': 'Refine respons data and Added geeExtractor', 'author': {'login': 'HanchengZuo'}, 'createdAt': '2024-01-25T19:23:46Z', 'updatedAt': '2024-01-26T10:17:28Z', 'closedAt': None, 'headRefName': 'refine-respons-data', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'Two main things:\\nfirstly restructuring the response data.\\nsecondly adding the GEE feature extractor to the GEE based dataset Dynamic World V1\\nOriginal response data:\\n\\nAdjusted response data:\\n\\nThe outer redundant FeatureCollection ;\\nattribute feature_name was originally intended to be the specified feature in the dataset for this one Feature, but it was not implemented so it is empty;\\nLayer_type indicates the source of the data.\\nAdded the dataset Dynamic World V1 from Google Earth Engine and the current response data is below:'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMNNX8', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Add pre-commit hooks', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/25', 'title': 'Add pre-commit hooks', 'author': {'login': 'jasonho2582001'}, 'createdAt': '2024-01-25T20:02:16Z', 'updatedAt': '2024-01-27T00:39:32Z', 'closedAt': '2024-01-27T00:39:29Z', 'headRefName': 'pre-commit-hooks', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'PR Description\\nThis PR introduces the changes to add pre-commit hooks for the black formatter, and for the pylint linter. These pre-commit hooks are created with the pre-commit library for Python. I chose this over husky since I did not want to introduce npm other other non-python package management into a Python repo. Additionally, to help with dealing with dependencies, I have removed the requirements.txt and dev-requirements.txt and now instead am using a Pipfile with the pipenv package.\\nThis PR closes #3.\\nUpdates\\n\\nAdd pre-commit hooks for Python\\nRemove requirements.txt and dev-requirements.txt\\nAdd Pipfile and usage for pipenv\\nUpdate README\\nAdd pyproject.toml'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMPiBM', 'fieldValues': {'nodes': [{}, {}, {}, {'text': 'Update response format of `searchDropzones` API', 'field': {'name': 'Title'}}, {'name': 'Done', 'field': {'name': 'Status'}}]}, 'content': {'url': 'https://github.com/UCL-Drone-Deliveries/dropzone/pull/28', 'title': 'Update response format of `searchDropzones` API', 'author': {'login': 'jasonho2582001'}, 'createdAt': '2024-01-27T14:30:01Z', 'updatedAt': '2024-01-27T15:05:00Z', 'closedAt': '2024-01-27T15:04:58Z', 'headRefName': 'update-response-format', 'headRepository': {'name': 'dropzone'}, 'bodyText': 'PR Description\\nRight now, the response structure of the searchDropzones API is not valid GeoJSON, since there can be instances of nested FeatureCollection objects. Rather than manually modify GeoJSON returned by APIs like OSMNX which may return FeatureCollection data depending on the query, the team has agreed to instead allow the API response to be a generic JSON object with the following structure:\\n{\\n    \"Layer 1\":  {\\n      \"type\": \"Feature\",\\n      \"geometry\": {\\n        \"type\": \"Point\",\\n        \"coordinates\": [0, 0]\\n      }\\n    },\\n    \"Combined\": {\\n      \"type\": \"Feature\",\\n      \"geometry\": {\\n        \"type\": \"Point\",\\n        \"coordinates\": [0, 0]\\n      }\\n    }\\n}\\nThis response is valid JSON, but we don\\'t force a constraint on this to be GeoJSON, but the values of each key in the JSON object is valid GeoJSON on its own. The format still allows for clients to easily manipulate the data as required.\\nThese changes have been verified with Postman, and the API correctly returns the required structure.\\nThis PR closes #27\\nUpdates\\n\\nRemoved method for converting dropzone layer data into a flat GeoJSON\\nUpdated search_dropzones to return JSON string of above format'}}, {'id': 'PVTI_lADOCQB6_84AYRaszgMQZvo', 'fieldValues': {'nodes': [{}, {'text': 'Figure out find places by drawn area fast query', 'field': {'name': 'Title'}}, {'name': 'Todo', 'field': {'name': 'Status'}}]}, 'content': {'title': 'Figure out find places by drawn area fast query', 'body': '', 'assignees': {'nodes': [{'login': 'Sree5835'}]}, 'createdAt': '2024-01-29T00:45:02Z', 'updatedAt': '2024-01-29T00:45:02Z', 'bodyText': ''}}]}}}}\n"
     ]
    }
   ],
   "source": [
    "org_name = \"UCL-Drone-Deliveries\"\n",
    "\n",
    "project_list_query = \"\"\"query{\n",
    "    organization(login: \"\"\"+'\"'+org_name+'\"'+\"\"\") {\n",
    "      projectsV2(first: 20) {\n",
    "        nodes {\n",
    "          id\n",
    "          title\n",
    "          createdAt\n",
    "          updatedAt\n",
    "          closedAt\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\"\"\"\n",
    "all_projects = github_graphql(project_list_query)\n",
    "\n",
    "project_id = all_projects[\"data\"][\"organization\"][\"projectsV2\"][\"nodes\"][1][\"id\"]\n",
    "\n",
    "print(project_id)\n",
    "\n",
    "\n",
    "\n",
    "project_query = '''{\n",
    "  node(id: \"'''+project_id+'''\") {\n",
    "    ... on ProjectV2 {\n",
    "      items(first:100) {\n",
    "        nodes {\n",
    "          id\n",
    "          fieldValues(first: 10) {\n",
    "            nodes {\n",
    "              ... on ProjectV2ItemFieldLabelValue {\n",
    "                labels(first: 10){\n",
    "                  nodes {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "                field {\n",
    "                  ... on ProjectV2FieldCommon {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              ... on ProjectV2ItemFieldTextValue {\n",
    "                text\n",
    "                field {\n",
    "                  ... on ProjectV2FieldCommon {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "              ... on ProjectV2ItemFieldSingleSelectValue {\n",
    "                name\n",
    "                field {\n",
    "                  ... on ProjectV2FieldCommon {\n",
    "                    name\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "          content {\n",
    "            ... on DraftIssue {\n",
    "              title\n",
    "              body\n",
    "              assignees(first: 10) {\n",
    "                nodes {\n",
    "                  login\n",
    "                }\n",
    "              }\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              bodyText\n",
    "            }\n",
    "            ... on Issue {\n",
    "              title\n",
    "              assignees(first: 10) {\n",
    "                nodes {\n",
    "                  login\n",
    "                }\n",
    "              }\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              closedAt\n",
    "              repository {\n",
    "                name\n",
    "              }\n",
    "              bodyText\n",
    "            }\n",
    "            ... on PullRequest {\n",
    "              url\n",
    "              title\n",
    "              author {\n",
    "                login\n",
    "              }\n",
    "              createdAt\n",
    "              updatedAt\n",
    "              closedAt\n",
    "              headRefName\n",
    "              headRepository {\n",
    "                name\n",
    "              }\n",
    "              bodyText\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}'''\n",
    "\n",
    "response = github_graphql(project_query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = response[\"data\"][\"node\"][\"items\"][\"nodes\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "def convert_fieldvalues_to_dict(items):\n",
    "    result = {}\n",
    "    for item in items:\n",
    "        # Check if 'text' and 'field' keys exist\n",
    "        if 'text' in item and 'field' in item and 'name' in item['field']:\n",
    "            key = item['field']['name']\n",
    "            value = item['text']\n",
    "            result[key] = value\n",
    "        # Check if 'name' and 'field' keys exist\n",
    "        elif 'name' in item and 'field' in item and 'name' in item['field']:\n",
    "            key = item['field']['name']\n",
    "            value = item['name']\n",
    "            result[key] = value\n",
    "        elif 'field' in item and item['field']['name'] == 'Labels':\n",
    "            key = item['field']['name']\n",
    "            value = []\n",
    "            for label in item['labels']['nodes']:\n",
    "                value.append(label['name'])\n",
    "            result[key] = value\n",
    "    return result\n",
    "\n",
    "\n",
    "# Extracting and processing data\n",
    "for item in data:\n",
    "    if item:\n",
    "        type = \"Task\"\n",
    "        item_id = item[\"id\"]\n",
    "        title = item[\"content\"][\"title\"]\n",
    "        repo = \"\"\n",
    "        if \"repository\" in item[\"content\"]:\n",
    "            repo = item[\"content\"][\"repository\"][\"name\"]\n",
    "        if \"body\" in item[\"content\"]:\n",
    "            body = item[\"content\"][\"body\"]\n",
    "        else:\n",
    "            body = \"\"\n",
    "        status = \"Not Started\"\n",
    "\n",
    "        field_values = convert_fieldvalues_to_dict(item[\"fieldValues\"][\"nodes\"])\n",
    "\n",
    "        if not title:\n",
    "            if \"Title\" in field_values:\n",
    "                title = field_values[\"Title\"]\n",
    "\n",
    "        if \"Status\" in field_values:\n",
    "            status = field_values[\"Status\"]\n",
    "        if \"url\" in item[\"content\"]:\n",
    "            type = \"Pull Request\"\n",
    "    \n",
    "        created_at = item[\"content\"][\"createdAt\"]\n",
    "        updated_at = item[\"content\"][\"updatedAt\"]\n",
    "\n",
    "        if \"closedAt\" in item[\"content\"] and item[\"content\"][\"closedAt\"]:\n",
    "            closed_at = item[\"content\"][\"closedAt\"]\n",
    "            closed_at_date = datetime.strptime(closed_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            updated_at_date = datetime.strptime(updated_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            if closed_at_date > updated_at_date:\n",
    "                updated_at = closed_at\n",
    "\n",
    "        # Its a PR\n",
    "        if \"author\" in item[\"content\"]:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"Id\": item_id,\n",
    "                    \"Type\": type,\n",
    "                    \"Title\": title,\n",
    "                    \"Body\": body,\n",
    "                    \"Assignee\": github_dict.get(\n",
    "                        item[\"content\"][\"author\"][\"login\"],\n",
    "                        item[\"content\"][\"author\"][\"login\"],\n",
    "                    ),\n",
    "                    \"Status\": status,\n",
    "                    \"Date\": updated_at,\n",
    "                    \"Branch\": item[\"content\"][\"headRefName\"],\n",
    "                    \"Repository\": item[\"content\"][\"headRepository\"][\"name\"],\n",
    "                    \"Labels\": field_values.get(\"Labels\", []),\n",
    "                    \"Description\": item[\"content\"][\"bodyText\"],\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            for assignee in item[\"content\"][\"assignees\"][\"nodes\"]:\n",
    "                # Append each assignee as a separate row\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"Id\": item_id,\n",
    "                        \"Type\": type,\n",
    "                        \"Title\": title,\n",
    "                        \"Body\": body,\n",
    "                        \"Assignee\": github_dict.get(\n",
    "                            assignee[\"login\"], assignee[\"login\"]\n",
    "                        ),\n",
    "                        \"Status\": status,\n",
    "                        \"Date\": updated_at,\n",
    "                        \"Repository\": repo,\n",
    "                        \"Labels\": field_values.get(\"Labels\", []),\n",
    "                        \"Description\": item[\"content\"][\"bodyText\"],\n",
    "                    }\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all Repositories, then create a commit entry for each commit\n",
    "\n",
    "\n",
    "getAllRepos = github_graphql('''query {\n",
    "  organization(login: \"'''+org_name+'''\") {\n",
    "    repositories(first: 100) {\n",
    "      edges {\n",
    "        node {\n",
    "          name\n",
    "          description\n",
    "          url\n",
    "        }\n",
    "      }\n",
    "      pageInfo {\n",
    "        endCursor\n",
    "        hasNextPage\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "def get_branches(repo_name):\n",
    "  return github_graphql('''query {\n",
    "  repository(name: \"'''+repo_name+'''\", owner: \"'''+org_name+'''\") {\n",
    "    refs(refPrefix: \"refs/heads/\", first: 100) {\n",
    "      edges {\n",
    "        node {\n",
    "          name\n",
    "        }\n",
    "      }\n",
    "      pageInfo {\n",
    "        endCursor\n",
    "        hasNextPage\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}''')\n",
    "\n",
    "def get_commits(repo_name, branch_name, since_date= \"2024-01-13T00:00:00Z\"):\n",
    "\n",
    "  return github_graphql('''query {\n",
    "    repository(name: \"'''+repo_name+'''\", owner: \"'''+org_name+'''\") {\n",
    "      ref(qualifiedName: \"'''+branch_name+'''\") {\n",
    "        target {\n",
    "          ... on Commit {\n",
    "            history(since: \"'''+since_date+'''\") {\n",
    "              edges {\n",
    "                node {\n",
    "                  message\n",
    "                  author {\n",
    "                    user {\n",
    "                      login\n",
    "                    }\n",
    "                  }\n",
    "                  committedDate\n",
    "                  authoredDate\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  ''')\n",
    "\n",
    "for repo in getAllRepos[\"data\"][\"organization\"][\"repositories\"][\"edges\"]:\n",
    "  repo_name = repo[\"node\"][\"name\"]\n",
    "  branches = get_branches(repo_name)\n",
    "  for branch in branches[\"data\"][\"repository\"][\"refs\"][\"edges\"]:\n",
    "    branch_name = branch[\"node\"][\"name\"]\n",
    "    commits = get_commits(repo_name, branch_name)\n",
    "\n",
    "    for commit in commits[\"data\"][\"repository\"][\"ref\"][\"target\"][\"history\"][\"edges\"]:\n",
    "      if commit[\"node\"][\"author\"] is None or not \"user\" in commit[\"node\"][\"author\"] or commit[\"node\"][\"author\"][\"user\"] is None:\n",
    "        continue\n",
    "      else:\n",
    "        authored_date_str = commit[\"node\"][\"authoredDate\"]\n",
    "        commited_date_str = commit[\"node\"][\"committedDate\"]\n",
    "        authored_date = datetime.strptime(authored_date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        commited_date = datetime.strptime(commited_date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        # Use the later date, compare them by serializing them as they come in strings like this: 2024-01-14T14:03:52Z\n",
    "        if commited_date > authored_date:\n",
    "          authored_date_str = commited_date_str\n",
    "\n",
    "        rows.append({\n",
    "          \"Type\": \"Commit\",\n",
    "          \"Title\": commit[\"node\"][\"message\"],\n",
    "          \"Body\": \"\",\n",
    "          \"Assignee\": github_dict.get(commit[\"node\"][\"author\"][\"user\"][\"login\"], commit[\"node\"][\"author\"][\"user\"][\"login\"]),\n",
    "          \"Status\": \"Done\",\n",
    "          \"Branch\": branch_name,\n",
    "          \"Repository\": repo_name,\n",
    "          \"Date\": authored_date_str\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Assuming 'df' is your original DataFrame\n",
    "# Convert 'Date' column to datetime without timezone\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"ISO8601\", errors='raise')\n",
    "\n",
    "# Filter out 'actions-user'\n",
    "df_filtered_since_friday_no_techusers = df[df[\"Assignee\"] != \"actions-user\"].copy()\n",
    "\n",
    "# Set 'Date' as the index\n",
    "df_filtered_since_friday_no_techusers.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensure the index is timezone-naive\n",
    "df_filtered_since_friday_no_techusers.index = df_filtered_since_friday_no_techusers.index.tz_localize(None)\n",
    "\n",
    "# Define 'friday' as a timezone-naive timestamp\n",
    "friday = pd.Timestamp(\"2024-01-19\").tz_localize(None)\n",
    "\n",
    "# Filter the DataFrame to include data since Friday\n",
    "df_filtered_since_friday = df_filtered_since_friday_no_techusers[df_filtered_since_friday_no_techusers.index >= friday].copy().reset_index(drop=True)\n",
    "\n",
    "df_filtered_since_friday.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignee_order = ['Ponmile', 'Lukas', 'Jason', 'James', 'Sree', 'Qitian', 'Mingzirui', 'Tianrui', 'Hancheng']\n",
    "\n",
    "# Convert 'Assignee' to a categorical type with the specified order\n",
    "df_filtered_since_friday['Assignee'] = pd.Categorical(df_filtered_since_friday['Assignee'], categories=assignee_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by 'Assignee'\n",
    "df_filtered_since_friday = df_filtered_since_friday.sort_values('Assignee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ponmile, these are your weekly GitHub stats:\n",
      "0 Pull Requests\n",
      "1 Tasks\n",
      "1 Commits (crane-spotting-image-processor)\n",
      "\n",
      "\t\n",
      "You had 1 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Produce alternative solution for current chosen camera\" (Done)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Lukas, these are your weekly GitHub stats:\n",
      "9 Pull Requests\n",
      "9 Tasks\n",
      "110 Commits (webapp, dropzone, crane-spotting)\n",
      "\n",
      "\t\n",
      "You had 7 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Fix compiler error\" (BLOCKED)\n",
      "    - \"Port to Cloud Functions v2 \" (Done)\n",
      "    - \"Move mapbox-gl secret into GCP secret and only inject in buildtime\" (Done)\n",
      "    - \"Increase test coverage \" (Done)\n",
      "    - \"Remove Leaflet components entirely\" (Done)\n",
      "    - \"Fix Prod Degradation\" (Done)\n",
      "    - \"CI/CD Pipeline Setup\" (Done)\n",
      "    - \"CI/CD Pipeline Setup\" (Done)\n",
      "    - \"Feature/make active button visible\" (Done)\n",
      "    - \"GitHub Actions Deployment Setup\" (Done)\n",
      "    - \"Feature/make active button visible\" (Done)\n",
      "    - \"Add webapp CI/CD\" (Done)\n",
      "    - \"EPIC: Complete initial Webapp setup\" (Done)\n",
      "    - \"CI/CD Pipeline Setup\" (Done)\n",
      "    - \"Fix/add correct images\" (Done)\n",
      "    - \"Investigate using Java as the main language\" (Done)\n",
      "    - \"Switch CD to 2nd gen cloud functions, tracking https://github.com/google-github-actions/deploy-cloud-functions/issues/304\" (Done)\n",
      "    - \"Remove leaflet, improve mapbox error handling and improve performance/bundle size\" (Done)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Jason, these are your weekly GitHub stats:\n",
      "4 Pull Requests\n",
      "6 Tasks\n",
      "100 Commits (dropzone, openapi)\n",
      "\n",
      "\t\n",
      "You had 2 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Set up generating docs on push\" (Done)\n",
      "    - \"Add Sphinx Document generation\" (Done)\n",
      "    - \"Set up PyLint, Black pre-commit hooks\" (Done)\n",
      "    - \"Modify response structure of `searchDropzones` API\" (Done)\n",
      "    - \"Set up bumpversion for dropzones\" (Done)\n",
      "    - \"Update the OpenAPI Documentation with the data you are returning\" (Done)\n",
      "    - \"Introduce bumpversion\" (Done)\n",
      "    - \"Add pre-commit hooks\" (Done)\n",
      "    - \"Update response format of `searchDropzones` API\" (Done)\n",
      "    - \"Add unit testing for dropzones\" (In Progress)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "James, these are your weekly GitHub stats:\n",
      "1 Pull Requests\n",
      "7 Tasks\n",
      "1 Commits (dropzone)\n",
      "\n",
      "\t\n",
      "You had 2 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Finish figma wireframing for the webapp\" (Done)\n",
      "    - \"Add frontend functionality to select multiple timestamps from which to render cranes on the map.\" (Done)\n",
      "    - \"Unclutter the crane spotting frontend map by implementing clustering with mapbox\" (Done)\n",
      "    - \"Slight refactor and beginning of styling from figma wireframes. \" (Done)\n",
      "    - \"Code to buffer exclusion polygons for use in calculating viable drop zones.\" (Done)\n",
      "    - \"Add webapp accessibility features\" (In Progress)\n",
      "    - \"Final refactor of the webapp -- including full styling from wireframes.\" (In Progress)\n",
      "    - \"Find a way to render different parts of an OSM map at different resolutions to save on computation time\" (In Progress)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Sree, these are your weekly GitHub stats:\n",
      "0 Pull Requests\n",
      "7 Tasks\n",
      "4 Commits (dropzone)\n",
      "\n",
      "\t\n",
      "You had 6 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Explore Google Earth Engine data in notebook\" (Done)\n",
      "    - \"Identify EE datasets relevant to dropzone mapping system\" (Done)\n",
      "    - \"Investigate caching osmnx querying for dropzone\" (Done)\n",
      "    - \"Set up PostGIS DB for cached drop zones\" (Done)\n",
      "    - \"Create a db manager class for other objects to interact with stored data\" (In Progress)\n",
      "    - \"figure out the solution for .shp osm dataset with poor data labeling\" (In Progress)\n",
      "    - \"Read up on OSM code and implement analytical drop zone identification\" (In Progress)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Qitian, these are your weekly GitHub stats:\n",
      "0 Pull Requests\n",
      "4 Tasks\n",
      "2 Commits (RTMP-Server)\n",
      "\n",
      "\t\n",
      "You had 3 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Use Spring Boot to initially create a project and attempt to invoke Google Cloud Storage (GCS)\" (Done)\n",
      "    - \"Research, discuss, and modify the Crane Spotting back end architecture.\" (Done)\n",
      "    - \"Modify the deployment view of crane spotting system\" (Done)\n",
      "    - \"Learn relative knowledge about RTMP server\" (In Progress)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Mingzirui, these are your weekly GitHub stats:\n",
      "0 Pull Requests\n",
      "5 Tasks\n",
      "9 Commits (crane-spotting)\n",
      "\n",
      "\t\n",
      "You had 5 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Initialize the VertexAI platform\" (Done)\n",
      "    - \"Try to use vision api directly\" (Done)\n",
      "    - \"Integrate the dataset and Distributed the dataset\" (Done)\n",
      "    - \"Train an initial model using vertex ai\" (Done)\n",
      "    - \"Deploy and test the model\" (Done)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Tianrui, these are your weekly GitHub stats:\n",
      "0 Pull Requests\n",
      "5 Tasks\n",
      "2 Commits (crane-spotting)\n",
      "\n",
      "\t\n",
      "You had 5 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Initialize the VertexAI platform\" (Done)\n",
      "    - \"Integrate the dataset and Distributed the dataset\" (Done)\n",
      "    - \"Train an initial model using vertex ai\" (Done)\n",
      "    - \"Try to use vision api directly\" (Done)\n",
      "    - \"Deploy and test the model\" (Done)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n",
      "Hancheng, these are your weekly GitHub stats:\n",
      "1 Pull Requests\n",
      "3 Tasks\n",
      "11 Commits (dropzone)\n",
      "\n",
      "\t\n",
      "You had 3 open tasks without acceptance criteria - please add acceptance criteria to all your items.\n",
      "\n",
      "Your tasks centered around the following topics:\n",
      "    - \"Refine respons data and Added geeExtractor\" (Done)\n",
      "    - \"Coding the landcover datasets on GEE\" (Done)\n",
      "    - \"Optimise the way and format of API response data\" (In Progress)\n",
      "    - \"Adding GEE feature extractor\" (In Progress)\n",
      "\n",
      "What you did well this week:\n",
      "\n",
      "What you could do better in the future:\n",
      "\n",
      "Next week you should focus on:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_text =  \"\"\n",
    "\n",
    "# Preprocessing steps\n",
    "df_filtered_since_friday[\"Title\"] = df_filtered_since_friday[\"Title\"].fillna(\"\").astype(str)\n",
    "df_filtered_since_friday[\"Repository\"] = df_filtered_since_friday[\"Repository\"].fillna(\"\").astype(str)\n",
    "df_filtered_since_friday[\"Description\"] = df_filtered_since_friday[\"Description\"].fillna(\"\").astype(str)\n",
    "\n",
    "df_final = df_filtered_since_friday.loc[df_filtered_since_friday['Status'] != \"Todo\"].copy()\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for selected_teammember in df_final[\"Assignee\"].dropna().unique():\n",
    "    # Filtering the DataFrame for the current assignee\n",
    "    df_filtered = df_final[df_final[\"Assignee\"] == selected_teammember]\n",
    "    non_commit_df = df_filtered[df_filtered[\"Type\"] != \"Commit\"].copy()\n",
    "\n",
    "    # Counting occurrences\n",
    "    pr_count = (df_filtered[\"Type\"] == \"Pull Request\").sum()\n",
    "    task_count = (df_filtered[\"Type\"] == \"Task\").sum()\n",
    "    commit_count = (df_filtered[\"Type\"] == \"Commit\").sum()\n",
    "\n",
    "    # topics\n",
    "    topics_df = df_filtered[df_filtered[\"Type\"] != \"Commit\"][[\"Title\", \"Status\"]]\n",
    "    topics_df_sorted = topics_df.sort_values(by=\"Status\")\n",
    "    topics = \"\\n    - \".join(\n",
    "        [f'\"{title}\" ({status})' for title, status in topics_df_sorted.values]\n",
    "    )\n",
    "\n",
    "    empty_description_mask = non_commit_df[\"Description\"] == \"\"\n",
    "    items_without_acceptance_criteria = non_commit_df[empty_description_mask]\n",
    "    items_without_acceptance_criteria = len(items_without_acceptance_criteria)\n",
    "    # Repos\n",
    "    repos = df_filtered.loc[df_filtered[\"Type\"] == \"Commit\", \"Repository\"].dropna().unique()\n",
    "    repos_list = [repo for repo in repos if repo]\n",
    "    repos_str = \", \".join(repos_list) if repos_list else \"No specific repositories\"\n",
    "\n",
    "    text = f\"\"\"{selected_teammember}, these are your weekly GitHub stats:\n",
    "{pr_count} Pull Requests\n",
    "{task_count} Tasks\n",
    "{commit_count} Commits ({repos_str})\n",
    "\n",
    "\t\n",
    "You had {items_without_acceptance_criteria} open tasks without acceptance criteria {\"- Great job!\" if items_without_acceptance_criteria == 0 else \"- please add acceptance criteria to all your tasks.\"}\n",
    "\n",
    "Your tasks centered around the following topics:\n",
    "    - {topics}\n",
    "\n",
    "What you did well this week:\n",
    "\n",
    "What you could do better in the future:\n",
    "\n",
    "Next week you should focus on:\n",
    "\n",
    "\"\"\"\n",
    "    print(text)\n",
    "\n",
    "    all_text += \"\\n\"+text\n",
    "\n",
    "\n",
    "with open(\"github_stats.txt\", \"w\") as file:\n",
    "    file.write(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
